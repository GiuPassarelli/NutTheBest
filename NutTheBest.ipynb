{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 13/Set at√© √†s 23:59.<br />\n",
    "Grupo: 1 ou 2 pessoas.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO disponibilizar o arquivo com os *access keys/tokens* do Twitter.**\n",
    "\n",
    "\n",
    "### Check 3: \n",
    "\n",
    "At√© o dia 06 de Setembro √†s 23:59, o notebook e o xlsx devem estar no Github com as seguintes evid√™ncias: \n",
    "    * Conta no twitter criada.\n",
    "    * Produto escolhido.\n",
    "    * Arquivo Excel contendo a base de treinamento e teste j√° classificado.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "http://docs.tweepy.org/en/v3.5.0/index.html<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Preparando o ambiente\n",
    "\n",
    "Instalando a biblioteca *tweepy* para realizar a conex√£o com o Twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as Bibliotecas que ser√£o utilizadas. Esteja livre para adicionar outras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "Para realizar a captura dos dados √© necess√°rio ter uma conta cadastrada no twitter:\n",
    "\n",
    "* Conta: *** @Rebecamoreno_***\n",
    "\n",
    "\n",
    "1. Caso ainda n√£o tenha uma: https://twitter.com/signup\n",
    "1. Depois √© necess√°rio registrar um app para usar a biblioteca: https://apps.twitter.com/\n",
    "1. Dentro do registro do App, na aba Keys and Access Tokens, anotar os seguintes campos:\n",
    "    1. Consumer Key (API Key)\n",
    "    1. Consumer Secret (API Secret)\n",
    "1. Mais abaixo, gere um Token e anote tamb√©m:\n",
    "    1. Access Token\n",
    "    1. Access Token Secret\n",
    "    \n",
    "1. Preencha os valores no arquivo \"auth.pass\"\n",
    "\n",
    "**ATEN√á√ÉO**: Nunca divulgue os dados desse arquivo online (GitHub, etc). Ele cont√©m as chaves necess√°rias para realizar as opera√ß√µes no twitter de forma autom√°tica e portanto √© equivalente a ser \"hackeado\". De posse desses dados, pessoas mal intencionadas podem fazer todas as opera√ß√µes manuais (tweetar, seguir, bloquear/desbloquear, listar os seguidores, etc). Para efeito do projeto, esse arquivo n√£o precisa ser entregue!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "\n",
    "#Coloque aqui o identificador da conta no twitter: @Rebecamoreno_\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando Dados\n",
    "\n",
    "Agora vamos coletar os dados. Tenha em mente que dependendo do produto escolhido, n√£o haver√° uma quantidade significativa de mensagens, ou ainda poder haver muitos retweets.<br /><br /> \n",
    "Configurando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Nutella'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1.\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang).items():    \n",
    "    msgs.append(msg.text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificando as Mensagens\n",
    "\n",
    "Agora voc√™ deve abrir o arquivo Excel com as mensagens capturadas e classificar na Coluna B se a mensagem √© relevante ou n√£o.<br /> \n",
    "N√£o se esque√ßa de colocar um nome para a coluna na c√©lula **B1**.<br /><br />\n",
    "Fazer o mesmo na planilha de Controle.\n",
    "\n",
    "___\n",
    "## Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Escreva o seu c√≥digo abaixo:\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_excel('./{0}.xlsx'.format(produto),sheet='Treinamento')\n",
    "\n",
    "dftsim = dft[(dft.Relevante==\"Sim\")]\n",
    "dftnao = dft[(dft.Relevante==\"N√£o\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lendo = pd.ExcelFile('./{0}.xlsx'.format(produto))\n",
    "dfteste = lendo.parse(\"Teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como curiosidade, a palavra que aparece com mais frequ√™ncia em toda essa an√°lise √© a palavra \"nutella\", com uma frenqu√™ncia de 219 vezes.\n",
      "\n",
      "Como curiosidade, a palavra que aparece com mais frequ√™ncia entre todas as palavras de RELEVANTES √© a palavra \"nutella\", com uma frenqu√™ncia de 135 vezes.\n",
      "\n",
      "Como curiosidade, a palavra que aparece com mais frequ√™ncia entre todas as palavras de N√ÉO RELEVANTES √© a palavra \"nutella\", com uma frenqu√™ncia de 84 vezes.\n",
      "\n",
      "A quantidade TOTAL de palavras no UNIVERSO √© 3774.\n",
      "A quantidade TOTAL de palavras dentro de RELEVANTES √© 1750.\n",
      "A quantidade TOTAL de palavras dentro de N√ÉO RELEVANTES √© 2024.\n",
      "\n",
      "A quantidade de palavras DIFERENTES no UNIVERSO √© 1370.\n",
      "A quantidade de palavras DIFERENTES dentro de RELEVANTES √© 636.\n",
      "A quantidade de palavras DIFERENTES dentro de N√ÉO RELEVANTES √© 917.\n"
     ]
    }
   ],
   "source": [
    "# A, S e N s√£o dicion√°rios com as frequ√™ncias de cada uma das palavras separadas (splitadas).\n",
    "A = {}\n",
    "S = {}\n",
    "N = {}\n",
    "todas = 0\n",
    "c=0\n",
    "#para cada post (msg)\n",
    "for msg in dft[\"Treinamento\"]:\n",
    "    #para cada palavra dentro do post (i)\n",
    "    #msg = msg.split()\n",
    "    for i in msg.split():\n",
    "        #analisando cada palavra ja separada (for e if)\n",
    "        for caracter in range(0,len(i)):\n",
    "            i = i.strip(\",\").strip(\"'\").strip('\"').strip('#').strip(':').strip(';').strip('!').strip('(').strip(')').strip('/').strip('\\n').strip('.').strip('\\\\').strip('-').strip('$').strip('%').strip('|').strip('=').strip('*').strip('ÀÜ').strip('&').strip('+').strip('?')\n",
    "        #contando sua frenquencia e adicionando em A\n",
    "        if not i in A:\n",
    "            A[i]=0\n",
    "        A[i]+=1\n",
    "        todas+=1\n",
    "        if A[i]>=c:\n",
    "            c=A[i]\n",
    "            string = i\n",
    "\n",
    "print('Como curiosidade, a palavra que aparece com mais frequ√™ncia em toda essa an√°lise √© a palavra \"{0}\", com uma frenqu√™ncia de {1} vezes.\\n'.format(string,c))\n",
    "todas_em_sim = 0\n",
    "p = 0\n",
    "#para cada post (msg)\n",
    "for msg in dftsim[\"Treinamento\"]:\n",
    "    #para cada palavra dentro do post (i)\n",
    "    #msg = msg.split()\n",
    "    for i in msg.split():\n",
    "        #analisando cada palavra ja separada (for e if)\n",
    "        for caracter in range(0,len(i)):\n",
    "            i = i.strip(\",\").strip(\"'\").strip('\"').strip('#').strip(':').strip(';').strip('!').strip('(').strip(')').strip('/').strip('\\n').strip('.').strip('\\\\').strip('-').strip('$').strip('%').strip('|').strip('=').strip('*').strip('ÀÜ').strip('&').strip('+').strip('?')\n",
    "        #contando sua frenquencia e adicionando em A\n",
    "        if not i in S:\n",
    "            S[i]=0\n",
    "        S[i]+=1\n",
    "        todas_em_sim+=1\n",
    "        if S[i]>=p:\n",
    "            p=S[i]\n",
    "            strings = i\n",
    "            \n",
    "print('Como curiosidade, a palavra que aparece com mais frequ√™ncia entre todas as palavras de RELEVANTES √© a palavra \"{0}\", com uma frenqu√™ncia de {1} vezes.\\n'.format(strings,p))\n",
    "todas_em_nao = 0\n",
    "f = 0\n",
    "#para cada post (msg)\n",
    "for msg in dftnao[\"Treinamento\"]:\n",
    "    #para cada palavra dentro do post (i)\n",
    "    #msg = msg.split()\n",
    "    for i in msg.split():\n",
    "        #analisando cada palavra ja separada (for e if)\n",
    "        for caracter in range(0,len(i)):\n",
    "            i = i.strip(\",\").strip(\"'\").strip('\"').strip('#').strip(':').strip(';').strip('!').strip('(').strip(')').strip('/').strip('\\n').strip('.').strip('\\\\').strip('-').strip('$').strip('%').strip('|').strip('=').strip('*').strip('ÀÜ').strip('&').strip('+').strip('?')\n",
    "        #contando sua frenquencia e adicionando em A\n",
    "        if not i in N:\n",
    "            N[i]=0\n",
    "        N[i]+=1\n",
    "        todas_em_nao+=1\n",
    "        if N[i]>=f:\n",
    "            f=N[i]\n",
    "            stringn = i\n",
    "            \n",
    "print('Como curiosidade, a palavra que aparece com mais frequ√™ncia entre todas as palavras de N√ÉO RELEVANTES √© a palavra \"{0}\", com uma frenqu√™ncia de {1} vezes.\\n'.format(stringn,f))\n",
    "print('A quantidade TOTAL de palavras no UNIVERSO √© {0}.'.format(todas))\n",
    "print('A quantidade TOTAL de palavras dentro de RELEVANTES √© {0}.'.format(todas_em_sim))\n",
    "print('A quantidade TOTAL de palavras dentro de N√ÉO RELEVANTES √© {0}.\\n'.format(todas_em_nao))\n",
    "print('A quantidade de palavras DIFERENTES no UNIVERSO √© {0}.'.format(len(A)))\n",
    "print('A quantidade de palavras DIFERENTES dentro de RELEVANTES √© {0}.'.format(len(S)))\n",
    "print('A quantidade de palavras DIFERENTES dentro de N√ÉO RELEVANTES √© {0}.'.format(len(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sim', 'sim', 'nao', 'sim', 'sim', 'sim', 'nao', 'sim', 'nao', 'sim', 'nao', 'sim', 'sim', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'sim', 'sim', 'sim', 'nao', 'sim', 'sim', 'sim', 'nao', 'nao', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'nao', 'nao', 'sim', 'nao', 'sim', 'sim', 'sim', 'sim', 'sim', 'nao', 'nao', 'sim', 'nao', 'nao', 'sim', 'nao', 'sim', 'nao', 'nao', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'nao', 'sim', 'sim', 'sim', 'nao', 'sim', 'nao', 'sim', 'sim', 'nao', 'sim', 'nao', 'nao', 'sim', 'sim', 'sim', 'sim', 'nao', 'nao', 'sim', 'sim', 'sim', 'sim', 'nao', 'nao', 'nao', 'sim', 'nao', 'sim', 'sim', 'nao', 'nao', 'sim', 'nao', 'sim', 'sim', 'nao', 'sim', 'sim', 'nao', 'nao', 'sim', 'nao', 'nao', 'sim', 'nao', 'nao', 'sim', 'nao', 'sim', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'sim', 'sim', 'nao', 'sim', 'nao', 'sim', 'nao', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'sim', 'nao', 'nao', 'sim', 'sim', 'nao', 'sim', 'sim', 'nao', 'nao', 'sim', 'sim', 'nao', 'nao', 'nao', 'sim', 'sim', 'nao', 'sim', 'nao', 'sim', 'sim', 'sim', 'sim', 'nao', 'sim', 'sim', 'sim', 'nao', 'nao', 'nao', 'nao', 'nao', 'nao', 'sim', 'nao', 'nao', 'nao', 'nao', 'sim', 'nao', 'sim', 'sim', 'sim', 'nao', 'nao', 'sim', 'nao', 'nao', 'sim', 'nao', 'nao', 'nao', 'sim', 'sim', 'nao', 'nao', 'nao', 'nao', 'nao', 'sim', 'nao', 'nao', 'sim']\n"
     ]
    }
   ],
   "source": [
    "#Calculando a probabilidade de cada palavra\n",
    "#Conta: P(sim|palavra)=(P(palavra|sim)+1) / P(palavras totais|sim)+P(palavras totais sem repeti√ß√£o)\n",
    "bs = todas_em_sim\n",
    "bn = todas_em_nao\n",
    "c = len(A)\n",
    "PS = {}\n",
    "PN = {}\n",
    "TSim = dftsim[\"Treinamento\"].count()\n",
    "TNao = dftnao[\"Treinamento\"].count()\n",
    "TTotal = dft[\"Treinamento\"].count()\n",
    "ListaPtweetS=[]\n",
    "ListaPtweetN=[]\n",
    "Resultado=[]\n",
    "addmsgs = []\n",
    "#PTeste = {}\n",
    "\n",
    "for msg2 in dfteste['Teste']:\n",
    "    #Para sim:\n",
    "    PtweetS = (TSim/TTotal)\n",
    "    for i in msg2.split():\n",
    "        #analisando cada palavra ja separada (for e if)\n",
    "        for caracter in range(0,len(i)):\n",
    "            i = i.strip(\",\").strip(\"'\").strip('\"').strip('#').strip(':').strip(';').strip('!').strip('(').strip(')').strip('/').strip('\\n').strip('.').strip('\\\\').strip('-').strip('$').strip('%').strip('|').strip('=').strip('*').strip('ÀÜ').strip('&').strip('+').strip('?')\n",
    "        #contando sua frenquencia e adicionando em A\n",
    "        \n",
    "        if i in S:\n",
    "            PS[i] = (S[i]+1)/(bs+c)\n",
    "            \n",
    "        else:\n",
    "            PS[i] = 1/(bs+c)\n",
    "            \n",
    "        PtweetS = PtweetS*PS[i]\n",
    "    ListaPtweetS.append(PtweetS)\n",
    "    addmsgs.append(msg2)\n",
    "        \n",
    "    #Para n√£o:\n",
    "    PtweetN = (TNao/TTotal)\n",
    "    for i in msg2.split():\n",
    "        #analisando cada palavra ja separada (for e if)\n",
    "        for caracter in range(0,len(i)):\n",
    "            i = i.strip(\",\").strip(\"'\").strip('\"').strip('#').strip(':').strip(';').strip('!').strip('(').strip(')').strip('/').strip('\\n').strip('.').strip('\\\\').strip('-').strip('$').strip('%').strip('|').strip('=').strip('*').strip('ÀÜ').strip('&').strip('+').strip('?')\n",
    "        #contando sua frenquencia e adicionando em A\n",
    "        \n",
    "        if i in N:\n",
    "            PN[i] = (N[i]+1)/(bn+c)\n",
    "            \n",
    "        else:\n",
    "            PN[i] = 1/(bn+c)\n",
    "        \n",
    "        PtweetN = PtweetN*PN[i]\n",
    "    ListaPtweetN.append(PtweetN)\n",
    "    #addmsgs.append(msg2)\n",
    "        \n",
    "for i in range(len(ListaPtweetS)):\n",
    "    #print(ListaPtweetS[i])\n",
    "    #print(ListaPtweetN[i])\n",
    "    if ListaPtweetS[i]>ListaPtweetN[i]:\n",
    "        Resultado.append(\"sim\")\n",
    "    if ListaPtweetN[i]>ListaPtweetS[i]:\n",
    "        Resultado.append(\"nao\")\n",
    "\n",
    "\n",
    "#dfteste[\"Resultado\"] = Resultado\n",
    "print(Resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @br00talgirl: espero um dia ser feliz igual...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adicionei um v√≠deo a uma playlist @youtube htt...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@pedronic_ @sleepool @gabriel0h @prdww lucas n...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preciso ir na casa do gui pra comer nutella kkj</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comecei ser fitness hj, comendo um bolo no pot...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nutella logo de manh√£ ‚ù§Ô∏è</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>passando a banana na nutella sem duplo sentido</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanto doce pra harmonizar e vcs insistem nessa...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt @ac_bulhoes: essa sua pele preta, nutella, ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>queria comer outra nutella</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rt @matheussvini: as vezes o ser humano so pre...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rt @_falathay: t√¥ comendo igual bicho</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>queria algu√©m s√≥ pra j√° saber quando t√¥ de tpm...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rt @marketingcrf: 2017: c√™ acredita, voz de mo...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rt @sigaarmandinho: aceito ir pra um lugar que...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@coemoren4 ali em botafogo menina, esse lugar ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ter algu√©m que te ame de vdd deve ser do caral...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017: c√™ acredita, voz de mongoloide do mc kev...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@nutella_a_mais meu afilhado mais querido ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rt @nxjvffc: se voce gosta nao custa nada demo...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rt @crvgluuhf: a pessoa s√≥ come√ßa a dar valor ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rt @_brunaa_silvaa_: @nutella_a_mais @xxevinha...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@luaracristal14 tem nutella aqui em casa</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>poucas coisas nesse mundo combinam t√£o bem qua...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>eu queria uma torta de leite ninho com nutella</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@danifields @gabrielfuh_ √© a propaganda gigant...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sonhei que mh tinha feito uma mesa cheia de cr...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>coisas muito superestimadas vol1:\\n1: sexo ana...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@breendinha_15 com nutella pelo amor üôèüèº</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@sportv hj √© a gera√ß√£o nutella !</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>a mana ganhou um pote de nutella imenso do av√¥...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>parab√©ns, nutella!\\ntmj irm√£o! https://t.co/he...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>foto de gatinho e de cachorrinho sempre faz su...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>√© muito engra√ßado o √°udio do matheus descreven...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>rt @brenolemes2016: que mina que n√£o gosta de ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>rt @renatotaioba: assistindo v√≠deos de receita...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>rt @saarahsaad: odiar ex √© mt gera√ß√£o nutella ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>arthur fez um bolo e levou hoje pro trabalho, ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>rt @isasantana2403: s√≥ queria um morango com n...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>https://t.co/56amzinurr\\nquero muito um pote d...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>rt @alexmapelli0: j√° fui 10/10 com quem n√£o me...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>eu sou a ex mais nutella que existe kkkkkkkkk</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>eu sou uma pessoa t√£o indecisa que t√¥ comendo ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>rt @umvicente: iago sousa n√£o est√° mais entre ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>gostei de um v√≠deo @youtube https://t.co/mzaqi...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>eu ganhei 2 bombons de leite ninho com nutella...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>rt @tmtisaac: adolesc√™ncia nutella// adolesc√™n...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>sdds do meu namorado n deu sinal de vida desde...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>rt @iioveviajar: jap√£o üáØüáµ https://t.co/ywg73hpglr</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>vou fazer pro gabriel de brigadeiro de leite n...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>comi o resto da nutella que tinha aqui, amanh√£...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>@kirchprincess vou hitar mais que o irm√£o do f...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>rt @09h08_: entao vamos viver, e um dia a gent...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>rt @viniceow: mais um dia sem achar o rumo da ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>rt @ac_bulhoes: essa sua pele preta, nutella, ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>@aguinaldinho pensamento retr√≥grado √© voc√™ cri...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>rt @portalechociay: um pouco de pote de nutell...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>imagina se eu fizesse text√£o no facebook toda ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rt @califaphotos: beijar s√≥ fortalece a amizad...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>achei dez conto na rua hoje, amanh√£ d√° pra eu ...</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste relevante\n",
       "0    rt @br00talgirl: espero um dia ser feliz igual...       sim\n",
       "1    adicionei um v√≠deo a uma playlist @youtube htt...       sim\n",
       "2    @pedronic_ @sleepool @gabriel0h @prdww lucas n...       sim\n",
       "3      preciso ir na casa do gui pra comer nutella kkj       sim\n",
       "4    comecei ser fitness hj, comendo um bolo no pot...       sim\n",
       "5                             nutella logo de manh√£ ‚ù§Ô∏è       sim\n",
       "6       passando a banana na nutella sem duplo sentido       sim\n",
       "7    tanto doce pra harmonizar e vcs insistem nessa...       sim\n",
       "8    rt @ac_bulhoes: essa sua pele preta, nutella, ...       sim\n",
       "9                           queria comer outra nutella       sim\n",
       "10   rt @matheussvini: as vezes o ser humano so pre...       sim\n",
       "11               rt @_falathay: t√¥ comendo igual bicho       sim\n",
       "12   queria algu√©m s√≥ pra j√° saber quando t√¥ de tpm...       sim\n",
       "13   rt @marketingcrf: 2017: c√™ acredita, voz de mo...       sim\n",
       "14   rt @sigaarmandinho: aceito ir pra um lugar que...       sim\n",
       "15   @coemoren4 ali em botafogo menina, esse lugar ...       sim\n",
       "16   ter algu√©m que te ame de vdd deve ser do caral...       sim\n",
       "17   2017: c√™ acredita, voz de mongoloide do mc kev...       sim\n",
       "18    @nutella_a_mais meu afilhado mais querido ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è       sim\n",
       "19   rt @nxjvffc: se voce gosta nao custa nada demo...       sim\n",
       "20   rt @crvgluuhf: a pessoa s√≥ come√ßa a dar valor ...       sim\n",
       "21   rt @_brunaa_silvaa_: @nutella_a_mais @xxevinha...       sim\n",
       "22            @luaracristal14 tem nutella aqui em casa       sim\n",
       "23   poucas coisas nesse mundo combinam t√£o bem qua...       sim\n",
       "24      eu queria uma torta de leite ninho com nutella       sim\n",
       "25   @danifields @gabrielfuh_ √© a propaganda gigant...       sim\n",
       "26   sonhei que mh tinha feito uma mesa cheia de cr...       sim\n",
       "27   coisas muito superestimadas vol1:\\n1: sexo ana...       sim\n",
       "28             @breendinha_15 com nutella pelo amor üôèüèº       sim\n",
       "29                    @sportv hj √© a gera√ß√£o nutella !       sim\n",
       "..                                                 ...       ...\n",
       "170  a mana ganhou um pote de nutella imenso do av√¥...       sim\n",
       "171  parab√©ns, nutella!\\ntmj irm√£o! https://t.co/he...       sim\n",
       "172  foto de gatinho e de cachorrinho sempre faz su...       sim\n",
       "173  √© muito engra√ßado o √°udio do matheus descreven...       sim\n",
       "174  rt @brenolemes2016: que mina que n√£o gosta de ...       sim\n",
       "175  rt @renatotaioba: assistindo v√≠deos de receita...       sim\n",
       "176  rt @saarahsaad: odiar ex √© mt gera√ß√£o nutella ...       sim\n",
       "177  arthur fez um bolo e levou hoje pro trabalho, ...       sim\n",
       "178  rt @isasantana2403: s√≥ queria um morango com n...       sim\n",
       "179  https://t.co/56amzinurr\\nquero muito um pote d...       sim\n",
       "180  rt @alexmapelli0: j√° fui 10/10 com quem n√£o me...       sim\n",
       "181      eu sou a ex mais nutella que existe kkkkkkkkk       sim\n",
       "182  eu sou uma pessoa t√£o indecisa que t√¥ comendo ...       sim\n",
       "183  rt @umvicente: iago sousa n√£o est√° mais entre ...       sim\n",
       "184  gostei de um v√≠deo @youtube https://t.co/mzaqi...       sim\n",
       "185  eu ganhei 2 bombons de leite ninho com nutella...       sim\n",
       "186  rt @tmtisaac: adolesc√™ncia nutella// adolesc√™n...       sim\n",
       "187  sdds do meu namorado n deu sinal de vida desde...       sim\n",
       "188  rt @iioveviajar: jap√£o üáØüáµ https://t.co/ywg73hpglr       sim\n",
       "189  vou fazer pro gabriel de brigadeiro de leite n...       sim\n",
       "190  comi o resto da nutella que tinha aqui, amanh√£...       sim\n",
       "191  @kirchprincess vou hitar mais que o irm√£o do f...       sim\n",
       "192  rt @09h08_: entao vamos viver, e um dia a gent...       sim\n",
       "193  rt @viniceow: mais um dia sem achar o rumo da ...       sim\n",
       "194  rt @ac_bulhoes: essa sua pele preta, nutella, ...       sim\n",
       "195  @aguinaldinho pensamento retr√≥grado √© voc√™ cri...       sim\n",
       "196  rt @portalechociay: um pouco de pote de nutell...       sim\n",
       "197  imagina se eu fizesse text√£o no facebook toda ...       sim\n",
       "198  rt @califaphotos: beijar s√≥ fortalece a amizad...       sim\n",
       "199  achei dez conto na rua hoje, amanh√£ d√° pra eu ...       sim\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listatestesimenao = ['sim']*200\n",
    "\n",
    "dfteste2 = {\"Teste\": addmsgs, 'relevante':listatestesimenao }\n",
    "dfteste = pd.DataFrame(dfteste2)\n",
    "dfteste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Opcionalmente:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
